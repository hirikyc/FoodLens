# -*- coding: utf-8 -*-
"""FoodLens.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b6YcmdXbwfbVmCsxwCFkoYazRZp_v5XO

## Install Package
"""

!pip install tensorflow scikit-learn opencv-python-headless

"""## Import Library"""

import os
import zipfile
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils.class_weight import compute_class_weight
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

"""## Mount Google Drive & Ekstrak Dataset"""

from google.colab import drive
drive.mount('/content/drive')
zip_path = '/content/drive/MyDrive/dataset/dataset_indonesian_food.zip'
extract_path = '/content/dataset/'
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)
dataset_path = os.path.join(extract_path, 'dataset_indonesian_food')

"""## Data Loading & Preprocessing"""

def display_image_with_label(image_path, label=None):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.imshow(img)
    if label:
        plt.title(label)
    plt.axis('off')
    plt.show()

def create_labeled_dataset(dataset_path):
    image_paths = []
    labels = []
    for class_folder in os.listdir(dataset_path):
        class_path = os.path.join(dataset_path, class_folder)
        if os.path.isdir(class_path):
            for image_file in os.listdir(class_path):
                if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_path = os.path.join(class_path, image_file)
                    image_paths.append(image_path)
                    labels.append(class_folder)
    df = pd.DataFrame({'image_path': image_paths, 'label': labels})
    return df
df = create_labeled_dataset(dataset_path)
for idx, row in df.head(5).iterrows():
    display_image_with_label(row['image_path'], row['label'])

def preprocess_image(image_path, target_size=(224, 224)):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, target_size)
    img = img.astype(np.float32) / 255.0
    return img
print("\nStatistik Dataset:")
print(f"Total gambar: {len(df)}")
print("\nJumlah gambar per kelas:")
print(df['label'].value_counts())

def visualize_preprocessing(image_path):
    original_img = cv2.imread(image_path)[..., ::-1]
    processed_img = preprocess_image(image_path)
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(original_img)
    plt.title('Original Image')
    plt.axis('off')
    plt.subplot(1, 2, 2)
    plt.imshow(processed_img)
    plt.title('Preprocessed Image')
    plt.axis('off')
    plt.show()
print("Contoh hasil preprocessing gambar:")
sample_image_path = df['image_path'].iloc[0]
visualize_preprocessing(sample_image_path)

def save_annotations(df, output_path):
    df.to_csv(output_path, index=False)
    print(f"Anotasi berhasil disimpan ke {output_path}")
save_annotations(df, 'food_annotations.csv')

"""## Data Split"""

train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)
val_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_dataframe(
    train_df,
    x_col='image_path',
    y_col='label',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)
val_gen = val_datagen.flow_from_dataframe(
    val_df,
    x_col='image_path',
    y_col='label',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_df['label']),
    y=train_df['label']
)
class_weights = dict(enumerate(class_weights))

callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)
]

"""### Model MobileNetV2"""

# Input layer
input_layer = Input(shape=(224, 224, 3))

# Pretrained MobileNetV2
base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=input_layer)
base_model.trainable = False

# Tambahan layers setelah pretrained
x = base_model.output
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = MaxPooling2D(2, 2)(x)

x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = MaxPooling2D(2, 2)(x)

x = GlobalAveragePooling2D()(x)
x = Dense(64, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)  # Dropout lebih besar untuk cegah overfitting

# Output layer
num_classes = df['label'].nunique()
output_layer = Dense(num_classes, activation='softmax')(x)

# Final model
model = Model(inputs=input_layer, outputs=output_layer)

# Compile model
model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# Model summary
model.summary()

"""## Training & Fine-Tuning

### Model MobileNetV2
"""

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=100,
    callbacks=callbacks,
    class_weight=class_weights
)

"""## Evaluasi Model

### Model MobileNetV2
"""

plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='val')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('MobileNetV2 Training & Validation Accuracy')
plt.show()

"""### Confussion Matrix & Classification Report (MobileNetV2)"""

y_true = []
y_pred = []
class_indices = train_gen.class_indices
idx_to_class = {v: k for k, v in class_indices.items()}
for i in range(len(val_gen)):
    x_batch, y_batch = val_gen[i]
    preds = model.predict(x_batch)
    y_true.extend(np.argmax(y_batch, axis=1))
    y_pred.extend(np.argmax(preds, axis=1))
    if (i+1)*val_gen.batch_size >= val_gen.n:
        break
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(class_indices.keys()), yticklabels=list(class_indices.keys()))
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix (MobileNetV2)')
plt.show()
print('\nClassification Report (MobileNetV2):')
print(classification_report(y_true, y_pred, target_names=list(class_indices.keys())))

def predict_image(image_path, model, class_indices):
    img = preprocess_image(image_path)
    pred = model.predict(np.expand_dims(img, axis=0))[0]
    idx_to_class = {v: k for k, v in class_indices.items()}
    pred_idx = np.argmax(pred)
    pred_label = idx_to_class[pred_idx]
    confidence = pred[pred_idx]
    return pred_label, confidence

"""## Inference"""

num_classes = len(df['label'].unique())
rows, cols = 10, 5
fig, axes = plt.subplots(rows, cols, figsize=(20, 40))
axes = axes.flatten()
for idx, label in enumerate(df['label'].unique()):
    if idx >= rows * cols:
        break
    sample_row = df[df['label'] == label].iloc[0]
    image_path = sample_row['image_path']
    pred_label, confidence = predict_image(image_path, model, train_gen.class_indices)
    img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)
    axes[idx].imshow(img)
    axes[idx].set_title(f"True: {label}\nPred: {pred_label}\nConf: {confidence:.2f}")
    axes[idx].axis('off')
for i in range(idx + 1, rows * cols):
    axes[i].axis('off')
plt.tight_layout()
plt.show()

print(df['label'].nunique())
print(len(train_gen.class_indices))
print(train_gen.class_indices)

"""### Save Model"""

model.save('model_indonesian_food.keras')
print("Model berhasil disimpan dalam format Keras: model_indonesian_food.keras")

model.save('model_indonesian_food.h5')
print("Model berhasil disimpan dalam format HDF5: model_indonesian_food.h5")

!pip install tensorflowjs
!tensorflowjs_converter --input_format=keras model_indonesian_food.keras model_tfjs/
print("Model berhasil dikonversi ke format TensorFlow.js")

